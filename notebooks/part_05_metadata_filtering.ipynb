{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Metadata & Filtering (Query Structuring)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand the importance of metadata in RAG systems\n",
    "2. Define metadata schemas for security documents\n",
    "3. Extract structured filters from natural language queries\n",
    "4. Implement metadata-aware retrieval\n",
    "5. Filter documents by severity, date, category, and other fields\n",
    "6. Compare filtered vs unfiltered retrieval\n",
    "7. Build production-ready query structuring\n",
    "\n",
    "## The Problem with Unfiltered Retrieval\n",
    "\n",
    "Pure similarity search has limitations for security use cases:\n",
    "\n",
    "### Example: \"Show me critical vulnerabilities\"\n",
    "\n",
    "**Without metadata filtering:**\n",
    "- Retrieves any document mentioning \"critical\" and \"vulnerabilities\"\n",
    "- May return Medium or Low severity vulnerabilities that mention the word \"critical\"\n",
    "- No guarantee the CVSS score is actually Critical (9.0+)\n",
    "- Can't filter by date, affected systems, or exploit status\n",
    "\n",
    "**With metadata filtering:**\n",
    "```python\n",
    "{\n",
    "  \"severity\": \"Critical\",\n",
    "  \"cvss_score\": {\"$gte\": 9.0}\n",
    "}\n",
    "```\n",
    "- Only returns documents with `severity = \"Critical\"`\n",
    "- Guaranteed to have CVSS >= 9.0\n",
    "- Can add date filters, product filters, etc.\n",
    "\n",
    "## Common Security Metadata\n",
    "\n",
    "### CVE/Vulnerability Metadata\n",
    "- **severity**: Critical, High, Medium, Low\n",
    "- **cvss_score**: 0.0 - 10.0\n",
    "- **date_published**: ISO date\n",
    "- **affected_products**: List of products/libraries\n",
    "- **exploit_available**: Boolean\n",
    "- **cwe_id**: Common Weakness Enumeration ID\n",
    "\n",
    "### MITRE ATT&CK Metadata\n",
    "- **tactic**: Initial Access, Execution, Persistence, etc.\n",
    "- **technique_id**: T1190, T1059, etc.\n",
    "- **platforms**: Windows, Linux, macOS, Cloud\n",
    "- **data_sources**: Process monitoring, network traffic, etc.\n",
    "\n",
    "### OWASP LLM Metadata\n",
    "- **vulnerability_id**: LLM01, LLM02, etc.\n",
    "- **risk_level**: Critical, High, Medium, Low\n",
    "- **category**: Input Validation, Output Handling, etc.\n",
    "- **source**: OWASP Top 10 for LLMs\n",
    "\n",
    "## Solution: Query Structuring\n",
    "\n",
    "1. **Extract structure from natural language**: Use LLM to parse filters\n",
    "2. **Apply metadata filters**: Combine with similarity search\n",
    "3. **Return precise results**: Only documents matching both semantic and metadata criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install additional dependencies\n",
    "!pip install -q pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Optional, Literal\n",
    "from datetime import datetime, timedelta\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è  WARNING: OPENAI_API_KEY not found\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings and LLM\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Embeddings and LLM initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Metadata Schema Definition\n",
    "\n",
    "We'll use Pydantic to define structured schemas for our security documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metadata schema using Pydantic\n",
    "class SecurityQueryFilter(BaseModel):\n",
    "    \"\"\"Structured filters for security document queries.\"\"\"\n",
    "    \n",
    "    # Severity/Risk filters\n",
    "    risk_level: Optional[Literal[\"Critical\", \"High\", \"Medium\", \"Low\"]] = Field(\n",
    "        None,\n",
    "        description=\"Filter by risk/severity level\"\n",
    "    )\n",
    "    \n",
    "    # Category filters\n",
    "    category: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Filter by vulnerability category (e.g., 'Input Validation', 'Output Handling')\"\n",
    "    )\n",
    "    \n",
    "    # ID filters\n",
    "    vulnerability_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Filter by specific vulnerability ID (e.g., 'LLM01', 'LLM02')\"\n",
    "    )\n",
    "    \n",
    "    # Source filters\n",
    "    source: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Filter by document source (e.g., 'OWASP Top 10 for LLMs', 'MITRE ATT&CK')\"\n",
    "    )\n",
    "    \n",
    "    # Free-text query (for hybrid filtering)\n",
    "    query: str = Field(\n",
    "        ...,\n",
    "        description=\"The semantic search query text\"\n",
    "    )\n",
    "\n",
    "print(\"‚úÖ Metadata schema defined\")\n",
    "print(\"\\nSchema fields:\")\n",
    "for field_name, field in SecurityQueryFilter.__fields__.items():\n",
    "    print(f\"  - {field_name}: {field.annotation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Structured Query Extraction\n",
    "\n",
    "We'll use LLM function calling to extract structured filters from natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parser for Pydantic model\n",
    "parser = PydanticOutputParser(pydantic_object=SecurityQueryFilter)\n",
    "\n",
    "# Prompt template for query structuring\n",
    "query_structuring_template = \"\"\"You are an AI assistant that converts natural language security queries into structured filters.\n",
    "\n",
    "Extract the following information from the user's query:\n",
    "1. risk_level: Critical, High, Medium, or Low (if mentioned)\n",
    "2. category: The vulnerability category (if mentioned)\n",
    "3. vulnerability_id: Specific vulnerability ID like LLM01, LLM02, etc. (if mentioned)\n",
    "4. source: The document source like \"OWASP Top 10 for LLMs\" (if mentioned)\n",
    "5. query: The semantic search query (always required)\n",
    "\n",
    "User query: {user_query}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Structured Query:\"\"\"\n",
    "\n",
    "query_structuring_prompt = ChatPromptTemplate.from_template(query_structuring_template)\n",
    "\n",
    "# Create chain\n",
    "query_structuring_chain = (\n",
    "    query_structuring_prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Query structuring chain created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query structuring\n",
    "test_queries = [\n",
    "    \"Show me critical vulnerabilities related to prompt injection\",\n",
    "    \"What are high severity output handling issues?\",\n",
    "    \"Tell me about LLM01\",\n",
    "    \"Find medium risk vulnerabilities in the OWASP Top 10\",\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing Query Structuring\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n‚ùì Natural Language: '{query}'\")\n",
    "    structured = query_structuring_chain.invoke({\"user_query\": query})\n",
    "    print(f\"\\nüìã Structured Filter:\")\n",
    "    print(f\"   risk_level: {structured.risk_level}\")\n",
    "    print(f\"   category: {structured.category}\")\n",
    "    print(f\"   vulnerability_id: {structured.vulnerability_id}\")\n",
    "    print(f\"   source: {structured.source}\")\n",
    "    print(f\"   query: '{structured.query}'\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Load Vector Store with Enhanced Metadata\n",
    "\n",
    "Let's load our existing vector store and examine the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vector store\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"owasp_llm_top10\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"../data/chroma_db\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Vector store loaded\")\n",
    "print(f\"   Collection: {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine metadata in our documents\n",
    "print(\"\\nüìä Metadata Schema in Current Documents:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get a sample document\n",
    "sample_docs = vectorstore.similarity_search(\"test\", k=1)\n",
    "if sample_docs:\n",
    "    sample_metadata = sample_docs[0].metadata\n",
    "    print(\"Sample document metadata:\")\n",
    "    for key, value in sample_metadata.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"No documents found\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Metadata-Aware Retrieval\n",
    "\n",
    "Now let's implement retrieval that combines similarity search with metadata filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_retrieval(\n",
    "    query: str,\n",
    "    vectorstore: Chroma,\n",
    "    filters: Optional[SecurityQueryFilter] = None,\n",
    "    k: int = 3\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Retrieve documents using semantic similarity + metadata filters.\n",
    "    \n",
    "    Args:\n",
    "        query: Semantic search query\n",
    "        vectorstore: Chroma vector store\n",
    "        filters: Structured metadata filters\n",
    "        k: Number of documents to retrieve\n",
    "        \n",
    "    Returns:\n",
    "        List of filtered documents\n",
    "    \"\"\"\n",
    "    # Build metadata filter dict for Chroma\n",
    "    where_filter = {}\n",
    "    \n",
    "    if filters:\n",
    "        if filters.risk_level:\n",
    "            where_filter[\"risk_level\"] = filters.risk_level\n",
    "        if filters.category:\n",
    "            where_filter[\"category\"] = filters.category\n",
    "        if filters.vulnerability_id:\n",
    "            where_filter[\"id\"] = filters.vulnerability_id\n",
    "        if filters.source:\n",
    "            where_filter[\"source\"] = filters.source\n",
    "    \n",
    "    # Perform filtered similarity search\n",
    "    if where_filter:\n",
    "        print(f\"üîç Searching with filters: {where_filter}\")\n",
    "        docs = vectorstore.similarity_search(\n",
    "            query=query,\n",
    "            k=k,\n",
    "            filter=where_filter\n",
    "        )\n",
    "    else:\n",
    "        print(f\"üîç Searching without filters\")\n",
    "        docs = vectorstore.similarity_search(query=query, k=k)\n",
    "    \n",
    "    return docs\n",
    "\n",
    "print(\"‚úÖ Filtered retrieval function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. End-to-End Query Structuring Pipeline\n",
    "\n",
    "Combine query structuring + filtered retrieval + answer generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def structured_query_rag(user_query: str, vectorstore: Chroma, llm) -> str:\n",
    "    \"\"\"\n",
    "    End-to-end RAG with query structuring and metadata filtering.\n",
    "    \n",
    "    Args:\n",
    "        user_query: Natural language query\n",
    "        vectorstore: Vector store\n",
    "        llm: Language model\n",
    "        \n",
    "    Returns:\n",
    "        Generated answer\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"‚ùì User Query: {user_query}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Step 1: Extract structured filters\n",
    "    print(\"1Ô∏è‚É£  Extracting structured filters...\")\n",
    "    structured = query_structuring_chain.invoke({\"user_query\": user_query})\n",
    "    print(f\"   Filters: risk_level={structured.risk_level}, category={structured.category}, id={structured.vulnerability_id}\")\n",
    "    print(f\"   Query: '{structured.query}'\\n\")\n",
    "    \n",
    "    # Step 2: Retrieve with filters\n",
    "    print(\"2Ô∏è‚É£  Retrieving documents...\")\n",
    "    docs = filtered_retrieval(\n",
    "        query=structured.query,\n",
    "        vectorstore=vectorstore,\n",
    "        filters=structured,\n",
    "        k=3\n",
    "    )\n",
    "    print(f\"   Retrieved {len(docs)} documents\\n\")\n",
    "    \n",
    "    if not docs:\n",
    "        return \"No documents found matching your criteria. Try broadening your search.\"\n",
    "    \n",
    "    # Show retrieved documents\n",
    "    print(\"   üìÑ Retrieved Documents:\")\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        print(f\"      {i}. {doc.metadata.get('id', 'N/A')}: {doc.metadata.get('title', 'N/A')} (Risk: {doc.metadata.get('risk_level', 'N/A')})\")\n",
    "    print()\n",
    "    \n",
    "    # Step 3: Generate answer\n",
    "    print(\"3Ô∏è‚É£  Generating answer...\\n\")\n",
    "    \n",
    "    # Format context\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Document {i+1} ({doc.metadata['id']} - {doc.metadata['title']}, Risk: {doc.metadata['risk_level']}):\\n{doc.page_content}\"\n",
    "        for i, doc in enumerate(docs)\n",
    "    ])\n",
    "    \n",
    "    # Answer prompt\n",
    "    answer_prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are an AI security expert assistant.\n",
    "\n",
    "Use the following security documentation to answer the user's question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Instructions:\n",
    "1. Provide a comprehensive answer based on the context\n",
    "2. Cite specific vulnerabilities (e.g., LLM01) and risk levels\n",
    "3. Include prevention measures and best practices\n",
    "4. Be specific and actionable\n",
    "5. If the context doesn't fully answer the question, acknowledge limitations\n",
    "\n",
    "Answer:\"\"\"\n",
    "    )\n",
    "    \n",
    "    prompt_value = answer_prompt.invoke({\"context\": context, \"question\": user_query})\n",
    "    response = llm.invoke(prompt_value)\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "print(\"‚úÖ Structured query RAG pipeline created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Demonstrations\n",
    "\n",
    "Let's test the structured query RAG system with various filtered queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Filter by Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = structured_query_rag(\n",
    "    \"Show me critical vulnerabilities\",\n",
    "    vectorstore,\n",
    "    llm\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÑ ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Filter by Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = structured_query_rag(\n",
    "    \"What are the output validation vulnerabilities?\",\n",
    "    vectorstore,\n",
    "    llm\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÑ ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Filter by Specific ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = structured_query_rag(\n",
    "    \"Tell me about LLM01\",\n",
    "    vectorstore,\n",
    "    llm\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÑ ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Combined Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = structured_query_rag(\n",
    "    \"Show me high severity data privacy issues\",\n",
    "    vectorstore,\n",
    "    llm\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÑ ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Comparison: Filtered vs Unfiltered Retrieval\n",
    "\n",
    "Let's compare retrieval quality with and without metadata filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_filtering(user_query: str, vectorstore: Chroma):\n",
    "    \"\"\"\n",
    "    Compare filtered vs unfiltered retrieval.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"‚ùì Query: {user_query}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Extract filters\n",
    "    structured = query_structuring_chain.invoke({\"user_query\": user_query})\n",
    "    \n",
    "    # Unfiltered retrieval\n",
    "    print(\"\\n1Ô∏è‚É£  UNFILTERED RETRIEVAL (Similarity Only)\")\n",
    "    print(\"-\" * 80)\n",
    "    unfiltered_docs = vectorstore.similarity_search(structured.query, k=3)\n",
    "    print(f\"Retrieved {len(unfiltered_docs)} documents:\\n\")\n",
    "    for i, doc in enumerate(unfiltered_docs, 1):\n",
    "        print(f\"{i}. {doc.metadata.get('id', 'N/A')}: {doc.metadata.get('title', 'N/A')}\")\n",
    "        print(f\"   Risk: {doc.metadata.get('risk_level', 'N/A')}, Category: {doc.metadata.get('category', 'N/A')}\")\n",
    "        print(f\"   Preview: {doc.page_content[:100]}...\\n\")\n",
    "    \n",
    "    # Filtered retrieval\n",
    "    print(\"\\n2Ô∏è‚É£  FILTERED RETRIEVAL (Similarity + Metadata)\")\n",
    "    print(\"-\" * 80)\n",
    "    filtered_docs = filtered_retrieval(structured.query, vectorstore, structured, k=3)\n",
    "    print(f\"\\nRetrieved {len(filtered_docs)} documents:\\n\")\n",
    "    for i, doc in enumerate(filtered_docs, 1):\n",
    "        print(f\"{i}. {doc.metadata.get('id', 'N/A')}: {doc.metadata.get('title', 'N/A')}\")\n",
    "        print(f\"   Risk: {doc.metadata.get('risk_level', 'N/A')}, Category: {doc.metadata.get('category', 'N/A')}\")\n",
    "        print(f\"   Preview: {doc.page_content[:100]}...\\n\")\n",
    "    \n",
    "    # Analysis\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Filters applied: risk_level={structured.risk_level}, category={structured.category}, id={structured.vulnerability_id}\")\n",
    "    print(f\"Unfiltered results: {len(unfiltered_docs)}\")\n",
    "    print(f\"Filtered results: {len(filtered_docs)}\")\n",
    "    print(f\"\\n‚úÖ Filtering ensures documents match both semantic similarity AND metadata criteria\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Comparison function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test comparison\n",
    "compare_filtering(\"Show me critical vulnerabilities\", vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another comparison\n",
    "compare_filtering(\"What are high severity input validation issues?\", vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Production Best Practices\n",
    "\n",
    "### Metadata Design Principles\n",
    "\n",
    "1. **Consistent Schema**: Use the same metadata fields across all documents\n",
    "2. **Controlled Vocabulary**: Use enums for categorical fields (e.g., severity levels)\n",
    "3. **Nullable Fields**: Make most fields optional to handle incomplete data\n",
    "4. **Rich Metadata**: Include all relevant filtering dimensions\n",
    "5. **Indexing**: Ensure metadata fields are indexed for fast filtering\n",
    "\n",
    "### Query Structuring Best Practices\n",
    "\n",
    "1. **Graceful Degradation**: If no structured filters found, fall back to semantic search\n",
    "2. **Validation**: Validate extracted filters before applying\n",
    "3. **User Feedback**: Show users what filters were applied\n",
    "4. **Refinement**: Allow users to adjust filters interactively\n",
    "5. **Logging**: Log structured queries for analysis and improvement\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "1. **Index Metadata Fields**: Ensure vector store indexes metadata for fast filtering\n",
    "2. **Limit Filter Complexity**: Too many filters can slow down queries\n",
    "3. **Cache Structured Queries**: Cache filter extraction for common queries\n",
    "4. **Batch Processing**: Process multiple queries in parallel when possible\n",
    "5. **Monitor Performance**: Track query latency and filter effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Graceful degradation\n",
    "def robust_structured_query_rag(user_query: str, vectorstore: Chroma, llm) -> str:\n",
    "    \"\"\"\n",
    "    RAG with graceful degradation if filter extraction fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try structured query extraction\n",
    "        structured = query_structuring_chain.invoke({\"user_query\": user_query})\n",
    "        docs = filtered_retrieval(structured.query, vectorstore, structured, k=3)\n",
    "        \n",
    "        # If no results with filters, try without\n",
    "        if not docs:\n",
    "            print(\"‚ö†Ô∏è  No results with filters, trying unfiltered search...\")\n",
    "            docs = vectorstore.similarity_search(structured.query, k=3)\n",
    "            \n",
    "    except Exception as e:\n",
    "        # If extraction fails, fall back to basic search\n",
    "        print(f\"‚ö†Ô∏è  Filter extraction failed ({e}), falling back to basic search...\")\n",
    "        docs = vectorstore.similarity_search(user_query, k=3)\n",
    "    \n",
    "    if not docs:\n",
    "        return \"No relevant documents found.\"\n",
    "    \n",
    "    # Generate answer\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    answer_prompt = ChatPromptTemplate.from_template(\n",
    "        \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\n",
    "    )\n",
    "    prompt_value = answer_prompt.invoke({\"context\": context, \"question\": user_query})\n",
    "    response = llm.invoke(prompt_value)\n",
    "    return response.content\n",
    "\n",
    "print(\"‚úÖ Robust structured query RAG created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Summary and Key Takeaways\n",
    "\n",
    "### What We Built\n",
    "\n",
    "‚úÖ Complete metadata filtering pipeline:\n",
    "1. **Metadata Schema**: Pydantic models for structured data\n",
    "2. **Query Structuring**: LLM-based filter extraction\n",
    "3. **Filtered Retrieval**: Combined similarity + metadata search\n",
    "4. **End-to-End RAG**: Complete pipeline with filtering\n",
    "5. **Comparison Framework**: Filtered vs unfiltered evaluation\n",
    "\n",
    "### Core Concepts Learned\n",
    "\n",
    "1. **Metadata Importance**: Why metadata is critical for production RAG\n",
    "2. **Structured Queries**: Converting natural language to filters\n",
    "3. **Hybrid Search**: Combining semantic + metadata filtering\n",
    "4. **Graceful Degradation**: Handling filter extraction failures\n",
    "5. **Production Patterns**: Best practices for real-world systems\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "**Metadata Filtering Benefits:**\n",
    "- ‚Üë‚Üë Precision (only relevant documents)\n",
    "- ‚Üë User control (explicit filter criteria)\n",
    "- ‚Üë Explainability (clear why documents matched)\n",
    "- ‚úÖ Essential for enterprise security applications\n",
    "\n",
    "**When to Use Metadata Filtering:**\n",
    "- **Categorical queries**: \"Show me critical vulnerabilities\"\n",
    "- **Time-bound queries**: \"CVEs from last 6 months\"\n",
    "- **Product-specific**: \"Vulnerabilities affecting PyTorch\"\n",
    "- **Compliance**: \"Show GDPR-relevant issues\"\n",
    "\n",
    "### Production Recommendations\n",
    "\n",
    "1. **Design metadata schema early**: Plan fields before indexing\n",
    "2. **Use controlled vocabularies**: Enums for consistency\n",
    "3. **Validate extracted filters**: Check before applying\n",
    "4. **Show filters to users**: Transparency builds trust\n",
    "5. **Monitor filter effectiveness**: Track precision/recall\n",
    "6. **Implement graceful degradation**: Fall back to semantic search\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **Part 6**, we'll add **Intelligent Reranking**:\n",
    "- Rerank by relevance AND priority (severity, recency)\n",
    "- Use Cohere Rerank for semantic reranking\n",
    "- Implement security-specific ranking functions\n",
    "- Combine multiple ranking signals\n",
    "\n",
    "Example: Boost critical vulnerabilities with recent exploits to the top, even if similarity score is slightly lower.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Practice Exercises\n",
    "\n",
    "1. **Add More Metadata Fields**: Add date_published, affected_products, exploit_available\n",
    "2. **Implement Date Filtering**: Parse date ranges from queries (\"last 6 months\")\n",
    "3. **Add CVSS Filtering**: Filter by CVSS score ranges\n",
    "4. **Build Interactive UI**: Streamlit app with filter controls\n",
    "5. **Implement Filter Suggestions**: Suggest relevant filters based on query\n",
    "\n",
    "### üìö Further Reading\n",
    "\n",
    "- [LangChain Self-Query Retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/self_query)\n",
    "- [Chroma Metadata Filtering](https://docs.trychroma.com/usage-guide#filtering-by-metadata)\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/)\n",
    "- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
