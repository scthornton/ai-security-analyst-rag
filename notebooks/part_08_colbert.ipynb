{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 8: Late Interaction Retrieval (ColBERT)\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "1. Understand ColBERT and late interaction retrieval\n",
    "2. Compare token-level vs document-level embeddings\n",
    "3. Implement MaxSim scoring mechanism\n",
    "4. Use RAGatouille for ColBERT indexing\n",
    "5. Apply ColBERT to code vulnerability patterns\n",
    "6. Compare ColBERT with dense embeddings\n",
    "7. Understand when to use ColBERT vs traditional embeddings\n",
    "\n",
    "## The Evolution of Retrieval Models\n",
    "\n",
    "### 1. Sparse Retrieval (BM25)\n",
    "```\n",
    "Query:  [\"sql\", \"injection\", \"prevention\"]\n",
    "Doc:    [\"sql\", \"injection\", \"attack\", \"prevention\", \"guide\"]\n",
    "Score:  Term frequency + IDF weighting\n",
    "```\n",
    "- ‚úÖ Fast, interpretable\n",
    "- ‚ùå No semantic understanding\n",
    "- ‚ùå Exact term matching only\n",
    "\n",
    "### 2. Dense Retrieval (Embeddings - what we've been using)\n",
    "```\n",
    "Query:  \"sql injection prevention\" ‚Üí [0.23, -0.45, 0.78, ...] (1536 dims)\n",
    "Doc:    \"guide to preventing SQL attacks\" ‚Üí [0.25, -0.43, 0.76, ...]\n",
    "Score:  cosine_similarity(query_vec, doc_vec)\n",
    "```\n",
    "- ‚úÖ Semantic understanding\n",
    "- ‚úÖ Fast at query time (pre-computed doc embeddings)\n",
    "- ‚ùå Single vector per document loses fine-grained information\n",
    "- ‚ùå No term-level interactions\n",
    "\n",
    "### 3. Late Interaction (ColBERT)\n",
    "```\n",
    "Query:  \"sql injection prevention\"\n",
    "  ‚Üí [\"sql\": [0.1, 0.2, ...], \"injection\": [0.3, 0.4, ...], \"prevention\": [0.5, 0.6, ...]]\n",
    "\n",
    "Doc:    \"guide to preventing SQL attacks\"\n",
    "  ‚Üí [\"guide\": [...], \"to\": [...], \"preventing\": [...], \"SQL\": [...], \"attacks\": [...]]\n",
    "\n",
    "Score:  MaxSim for each query token across all doc tokens\n",
    "```\n",
    "- ‚úÖ Token-level semantic understanding\n",
    "- ‚úÖ Captures both semantic AND lexical matches\n",
    "- ‚úÖ Better for technical terms, code, identifiers\n",
    "- ‚ùå Slower than dense embeddings (more vectors to compare)\n",
    "- ‚ùå Larger index size\n",
    "\n",
    "## ColBERT: Contextualized Late Interaction over BERT\n",
    "\n",
    "### Key Innovation: MaxSim Scoring\n",
    "\n",
    "For each query token, find the most similar document token:\n",
    "\n",
    "```python\n",
    "score = Œ£ max(similarity(q_token_i, d_token_j) for all j)\n",
    "        for all query tokens i\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "```\n",
    "Query: \"SQL injection\"\n",
    "  q_token[0] = \"SQL\" embedding\n",
    "  q_token[1] = \"injection\" embedding\n",
    "\n",
    "Doc: \"Prevent SQL attacks and code injection\"\n",
    "  d_token[0] = \"Prevent\"\n",
    "  d_token[1] = \"SQL\" ‚Üê Matches q_token[0]\n",
    "  d_token[2] = \"attacks\"\n",
    "  d_token[3] = \"and\"\n",
    "  d_token[4] = \"code\"\n",
    "  d_token[5] = \"injection\" ‚Üê Matches q_token[1]\n",
    "\n",
    "Score = max_sim(q[0], d[*]) + max_sim(q[1], d[*])\n",
    "      = sim(q[0], d[1]) + sim(q[1], d[5])\n",
    "      = 0.95 + 0.98 = 1.93\n",
    "```\n",
    "\n",
    "## Why ColBERT for Security?\n",
    "\n",
    "1. **Technical Jargon**: \"LSASS\", \"NTDS\", \"CVE-2024-1234\"\n",
    "2. **Code Patterns**: Function names, variable names, code snippets\n",
    "3. **Exploit Signatures**: Specific attack patterns\n",
    "4. **Precise Matching**: Both semantic meaning AND exact terms\n",
    "5. **Mixed Content**: Natural language + code + identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install RAGatouille (ColBERT wrapper)\n",
    "!pip install -q ragatouille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import List, Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "# RAGatouille for ColBERT\n",
    "from ragatouille import RAGPretrainedModel\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"‚ö†Ô∏è  WARNING: OPENAI_API_KEY not found\")\n",
    "else:\n",
    "    print(\"‚úÖ OpenAI API key loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize standard embeddings and LLM (for comparison)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Standard embeddings and LLM initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our existing vector store\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"owasp_llm_top10\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"../data/chroma_db\"\n",
    ")\n",
    "\n",
    "# Get all documents\n",
    "all_docs = vectorstore.similarity_search(\"\", k=100)\n",
    "\n",
    "print(\"‚úÖ Vector store loaded\")\n",
    "print(f\"   Total documents: {len(all_docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. ColBERT with RAGatouille\n",
    "\n",
    "RAGatouille is a wrapper around ColBERT that makes it easy to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RAGatouille ColBERT model\n",
    "print(\"üîÑ Initializing ColBERT model (this may download the model on first run)...\\n\")\n",
    "\n",
    "colbert_model = RAGPretrainedModel.from_pretrained(\"colbert-ir/colbertv2.0\")\n",
    "\n",
    "print(\"‚úÖ ColBERT model initialized\")\n",
    "print(\"   Model: colbert-ir/colbertv2.0\")\n",
    "print(\"   Token-level embeddings: 128 dimensions per token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Index Documents with ColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare documents for ColBERT indexing\n",
    "# ColBERT expects a list of strings\n",
    "colbert_documents = [doc.page_content for doc in all_docs]\n",
    "document_ids = [f\"doc_{i}\" for i in range(len(all_docs))]\n",
    "\n",
    "print(f\"üìÑ Preparing {len(colbert_documents)} documents for ColBERT indexing...\")\n",
    "print(f\"   Average document length: {sum(len(d) for d in colbert_documents) / len(colbert_documents):.0f} characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index documents with ColBERT\n",
    "# This creates token-level embeddings for each document\n",
    "print(\"\\nüîÑ Indexing documents with ColBERT...\")\n",
    "print(\"   This may take a few minutes...\\n\")\n",
    "\n",
    "index_name = \"owasp_security_colbert\"\n",
    "index_path = f\"../data/{index_name}\"\n",
    "\n",
    "colbert_model.index(\n",
    "    collection=colbert_documents,\n",
    "    document_ids=document_ids,\n",
    "    index_name=index_name,\n",
    "    max_document_length=512,  # Maximum tokens per document\n",
    "    split_documents=True  # Automatically split long documents\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ ColBERT indexing complete!\")\n",
    "print(f\"   Index saved to: {index_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Query with ColBERT (MaxSim Scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colbert_search(query: str, k: int = 3) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Search using ColBERT with MaxSim scoring.\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        k: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        List of search results with scores\n",
    "    \"\"\"\n",
    "    results = colbert_model.search(\n",
    "        query=query,\n",
    "        k=k\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ ColBERT search function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ColBERT search\n",
    "test_query = \"prompt injection attacks\"\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"üîç ColBERT Search: '{test_query}'\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = colbert_search(test_query, k=3)\n",
    "\n",
    "print(f\"\\nTop {len(results)} results:\\n\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"{i}. Score: {result['score']:.4f}\")\n",
    "    print(f\"   Document ID: {result['document_id']}\")\n",
    "    print(f\"   Content: {result['content'][:200]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Comparison: ColBERT vs Dense Embeddings\n",
    "\n",
    "Let's compare ColBERT with our standard dense embeddings on various query types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_retrieval_methods(query: str, vectorstore, k: int = 3):\n",
    "    \"\"\"\n",
    "    Compare ColBERT vs dense embeddings retrieval.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"‚ùì Query: {query}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Dense embeddings (OpenAI)\n",
    "    print(\"\\n1Ô∏è‚É£  DENSE EMBEDDINGS (OpenAI text-embedding-3-small)\")\n",
    "    print(\"-\"*80)\n",
    "    dense_results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "    print(f\"Retrieved {len(dense_results)} documents:\\n\")\n",
    "    for i, (doc, score) in enumerate(dense_results, 1):\n",
    "        print(f\"{i}. Distance: {score:.4f} | {doc.metadata.get('id')}: {doc.metadata.get('title')}\")\n",
    "        print(f\"   Preview: {doc.page_content[:150]}...\\n\")\n",
    "    \n",
    "    # ColBERT\n",
    "    print(\"\\n2Ô∏è‚É£  COLBERT (Token-Level Late Interaction)\")\n",
    "    print(\"-\"*80)\n",
    "    colbert_results = colbert_search(query, k=k)\n",
    "    print(f\"Retrieved {len(colbert_results)} documents:\\n\")\n",
    "    for i, result in enumerate(colbert_results, 1):\n",
    "        print(f\"{i}. Score: {result['score']:.4f}\")\n",
    "        print(f\"   Preview: {result['content'][:150]}...\\n\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìä ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚úÖ Dense: Fast, good for semantic similarity\")\n",
    "    print(\"‚úÖ ColBERT: Better for technical terms, code, precise matching\")\n",
    "    print(\"‚úÖ ColBERT: Captures both semantic AND lexical matches\")\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"‚úÖ Comparison function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 1: Technical Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_retrieval_methods(\n",
    "    \"LLM01 prompt injection\",\n",
    "    vectorstore,\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 2: Semantic Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_retrieval_methods(\n",
    "    \"How can attackers manipulate AI systems?\",\n",
    "    vectorstore,\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case 3: Mixed (Semantic + Technical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_retrieval_methods(\n",
    "    \"OWASP LLM security risks and mitigations\",\n",
    "    vectorstore,\n",
    "    k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Complete RAG with ColBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_with_colbert(\n",
    "    query: str,\n",
    "    llm,\n",
    "    k: int = 3\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline using ColBERT retrieval.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"üîç RAG with ColBERT\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Retrieve with ColBERT\n",
    "    print(f\"1Ô∏è‚É£  Retrieving with ColBERT (token-level matching)...\")\n",
    "    results = colbert_search(query, k=k)\n",
    "    print(f\"   Retrieved {len(results)} documents\\n\")\n",
    "    \n",
    "    # Format context\n",
    "    context = \"\\n\\n\".join([\n",
    "        f\"Document {i+1} (ColBERT Score: {result['score']:.4f}):\\n{result['content']}\"\n",
    "        for i, result in enumerate(results)\n",
    "    ])\n",
    "    \n",
    "    # Generate answer\n",
    "    print(\"2Ô∏è‚É£  Generating answer...\\n\")\n",
    "    \n",
    "    answer_prompt = ChatPromptTemplate.from_template(\n",
    "        \"\"\"You are an AI security expert assistant using ColBERT token-level retrieval.\n",
    "\n",
    "The context below was retrieved using precise token-level matching, capturing both semantic meaning and exact technical terms.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Question: {question}\n",
    "\n",
    "Instructions:\n",
    "1. Provide a comprehensive answer based on the precisely matched context\n",
    "2. Leverage the technical accuracy from token-level matching\n",
    "3. Include specific security recommendations\n",
    "4. Cite relevant vulnerability IDs and technical terms\n",
    "\n",
    "Answer:\"\"\"\n",
    "    )\n",
    "    \n",
    "    prompt_value = answer_prompt.invoke({\"context\": context, \"question\": query})\n",
    "    response = llm.invoke(prompt_value)\n",
    "    \n",
    "    return response.content\n",
    "\n",
    "print(\"‚úÖ RAG with ColBERT pipeline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test complete RAG with ColBERT\n",
    "query = \"What are the prevention measures for LLM01 prompt injection?\"\n",
    "\n",
    "answer = rag_with_colbert(\n",
    "    query=query,\n",
    "    llm=llm,\n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìÑ ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(answer)\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Use Case: Code Vulnerability Patterns\n",
    "\n",
    "ColBERT excels at matching code patterns and technical identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code vulnerability documents\n",
    "code_docs = [\n",
    "    \"\"\"SQL Injection Example:\n",
    "```python\n",
    "# Vulnerable code\n",
    "query = f\"SELECT * FROM users WHERE username = '{user_input}'\"\n",
    "cursor.execute(query)\n",
    "```\n",
    "This is vulnerable to SQL injection. An attacker could input: ' OR '1'='1\n",
    "\"\"\",\n",
    "    \"\"\"Cross-Site Scripting (XSS) Example:\n",
    "```javascript\n",
    "// Vulnerable code\n",
    "element.innerHTML = userInput;\n",
    "```\n",
    "This allows script injection. Use textContent instead or sanitize input.\n",
    "\"\"\",\n",
    "    \"\"\"Command Injection Example:\n",
    "```python\n",
    "# Vulnerable code\n",
    "os.system(f\"ping {user_input}\")\n",
    "```\n",
    "Attacker could inject: 8.8.8.8; rm -rf /\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "print(\"üíª Code Vulnerability Pattern Matching\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nColBERT is excellent for matching code patterns because:\")\n",
    "print(\"1. Token-level matching captures function names, variables\")\n",
    "print(\"2. Preserves code structure and syntax\")\n",
    "print(\"3. Matches both semantic intent AND exact identifiers\")\n",
    "print(\"\\nExample queries that benefit from ColBERT:\")\n",
    "print(\"  - 'Find SQL injection in Python code'\")\n",
    "print(\"  - 'Show XSS vulnerabilities with innerHTML'\")\n",
    "print(\"  - 'Locate os.system command injection'\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. When to Use ColBERT vs Dense Embeddings\n",
    "\n",
    "### Use ColBERT When:\n",
    "\n",
    "1. **Technical Content**\n",
    "   - Code snippets and patterns\n",
    "   - Function names, APIs, identifiers\n",
    "   - Technical jargon and acronyms\n",
    "   - Version numbers, CVE IDs\n",
    "\n",
    "2. **Precise Matching Required**\n",
    "   - Security signatures\n",
    "   - Exploit patterns\n",
    "   - Configuration examples\n",
    "   - Command-line syntax\n",
    "\n",
    "3. **Mixed Content**\n",
    "   - Natural language + code\n",
    "   - Documentation with examples\n",
    "   - Technical guides with syntax\n",
    "\n",
    "### Use Dense Embeddings When:\n",
    "\n",
    "1. **Pure Natural Language**\n",
    "   - Concept explanations\n",
    "   - High-level overviews\n",
    "   - General knowledge questions\n",
    "\n",
    "2. **Speed is Critical**\n",
    "   - Real-time search (<100ms)\n",
    "   - Large-scale retrieval (millions of docs)\n",
    "   - Resource-constrained environments\n",
    "\n",
    "3. **Semantic Similarity Only**\n",
    "   - Paraphrase matching\n",
    "   - Conceptual similarity\n",
    "   - Topic clustering\n",
    "\n",
    "### Hybrid Approach (Best of Both):\n",
    "\n",
    "1. **Dense for initial retrieval** (fast, top 50-100)\n",
    "2. **ColBERT for reranking** (precise, top 10)\n",
    "3. **Combine scores** with weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Production Considerations\n",
    "\n",
    "### Index Size and Storage\n",
    "\n",
    "```python\n",
    "# Dense embeddings\n",
    "1000 documents √ó 1536 dimensions √ó 4 bytes = 6.14 MB\n",
    "\n",
    "# ColBERT (token-level)\n",
    "1000 documents √ó avg 200 tokens √ó 128 dimensions √ó 4 bytes = 102 MB\n",
    "```\n",
    "\n",
    "**ColBERT is ~16-20x larger than dense embeddings**\n",
    "\n",
    "### Query Latency\n",
    "\n",
    "```\n",
    "Dense embeddings:  10-50ms  (single dot product per doc)\n",
    "ColBERT:          50-200ms  (MaxSim across all tokens)\n",
    "```\n",
    "\n",
    "**ColBERT is ~5-10x slower than dense embeddings**\n",
    "\n",
    "### Optimization Strategies\n",
    "\n",
    "1. **Use ColBERT selectively**\n",
    "   - Only for technical/code queries\n",
    "   - Classify query type first\n",
    "   - Route to appropriate retriever\n",
    "\n",
    "2. **Two-stage retrieval**\n",
    "   - Stage 1: Dense retrieval (top 50)\n",
    "   - Stage 2: ColBERT rerank (top 10)\n",
    "\n",
    "3. **Cache results**\n",
    "   - Cache frequent queries\n",
    "   - Cache ColBERT embeddings\n",
    "\n",
    "4. **Hardware acceleration**\n",
    "   - Use GPU for ColBERT\n",
    "   - Batch queries when possible\n",
    "\n",
    "### When NOT to Use ColBERT\n",
    "\n",
    "- Very large corpora (10M+ documents) without GPU\n",
    "- Real-time latency requirements (<50ms)\n",
    "- Memory-constrained environments\n",
    "- Pure concept-based retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Summary and Key Takeaways\n",
    "\n",
    "### What We Built\n",
    "\n",
    "‚úÖ Complete ColBERT implementation:\n",
    "1. **ColBERT with RAGatouille**: Token-level embeddings and indexing\n",
    "2. **MaxSim Scoring**: Late interaction retrieval mechanism\n",
    "3. **Comparison Framework**: ColBERT vs dense embeddings\n",
    "4. **Complete RAG Pipeline**: End-to-end with ColBERT\n",
    "5. **Use Case Analysis**: When to use each approach\n",
    "6. **Production Considerations**: Performance and optimization\n",
    "\n",
    "### Core Concepts Learned\n",
    "\n",
    "1. **Late Interaction**: Delay interaction between query and document to token level\n",
    "2. **Token-Level Embeddings**: Each token gets its own embedding\n",
    "3. **MaxSim Scoring**: Maximum similarity for each query token\n",
    "4. **Hybrid Retrieval**: Combining dense + late interaction\n",
    "5. **Trade-offs**: Accuracy vs speed vs storage\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "**ColBERT Strengths:**\n",
    "- ‚Üë‚Üë Better for technical content (code, identifiers, jargon)\n",
    "- ‚Üë‚Üë Precise matching (semantic AND lexical)\n",
    "- ‚Üë Captures token-level interactions\n",
    "- ‚úÖ Essential for security patterns and code\n",
    "\n",
    "**ColBERT Limitations:**\n",
    "- ‚Üì Slower than dense embeddings (5-10x)\n",
    "- ‚Üì Larger index size (16-20x)\n",
    "- ‚Üì More complex infrastructure\n",
    "\n",
    "**Best Practice: Hybrid**\n",
    "- Use dense for speed and scale\n",
    "- Use ColBERT for precision\n",
    "- Combine both for best results\n",
    "\n",
    "### Production Recommendations\n",
    "\n",
    "1. **Query Classification**: Route queries to appropriate retriever\n",
    "2. **Two-Stage Retrieval**: Dense ‚Üí ColBERT rerank\n",
    "3. **Selective Use**: Only for technical/code content\n",
    "4. **GPU Acceleration**: Use GPU for ColBERT at scale\n",
    "5. **Caching**: Cache frequent ColBERT results\n",
    "6. **Monitor Performance**: Track latency and quality\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **Part 9**, we'll focus on **Security Hardening**:\n",
    "- Detect prompt injection in queries\n",
    "- Prevent jailbreaking attempts\n",
    "- Implement source verification\n",
    "- Add confidence scoring\n",
    "- Redact sensitive information\n",
    "- Validate outputs for safety\n",
    "\n",
    "Making the RAG system itself secure against adversarial use!\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Practice Exercises\n",
    "\n",
    "1. **Index Code Repository**: Index a code repository with ColBERT\n",
    "2. **Build Hybrid Retriever**: Combine dense + ColBERT with weights\n",
    "3. **Benchmark Performance**: Measure latency and quality\n",
    "4. **Query Classification**: Build router to select retriever\n",
    "5. **Optimize Index**: Tune ColBERT parameters for your use case\n",
    "\n",
    "### üìö Further Reading\n",
    "\n",
    "- [ColBERT Paper](https://arxiv.org/abs/2004.12832)\n",
    "- [ColBERTv2 Paper](https://arxiv.org/abs/2112.01488)\n",
    "- [RAGatouille Documentation](https://github.com/bclavie/RAGatouille)\n",
    "- [Late Interaction Models](https://arxiv.org/abs/2104.01967)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
