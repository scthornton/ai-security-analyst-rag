{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 11: Deployment & Demo - Building a Production RAG Application\n",
    "\n",
    "## Overview\n",
    "\n",
    "We've built a comprehensive RAG system across 10 parts. Now it's time to **deploy it** as a production-ready web application!\n",
    "\n",
    "### What We've Built\n",
    "\n",
    "1. ‚úÖ **Basic RAG** - Foundation\n",
    "2. ‚úÖ **Multi-Query** - Broader coverage\n",
    "3. ‚úÖ **RAG-Fusion** - Improved ranking\n",
    "4. ‚úÖ **Query Decomposition** - Complex questions\n",
    "5. ‚úÖ **Metadata Filtering** - Precise retrieval\n",
    "6. ‚úÖ **Reranking** - Business-aware prioritization\n",
    "7. ‚úÖ **RAPTOR** - Hierarchical knowledge\n",
    "8. ‚úÖ **ColBERT** - Token-level matching\n",
    "9. ‚úÖ **Security Hardening** - Adversarial defense\n",
    "10. ‚úÖ **Evaluation** - Quality measurement\n",
    "\n",
    "### What We're Building Now\n",
    "\n",
    "A **Streamlit web application** that:\n",
    "- Provides an interactive query interface\n",
    "- Shows real-time responses with streaming\n",
    "- Displays source citations and confidence scores\n",
    "- Offers multiple RAG configuration options\n",
    "- Maintains chat history\n",
    "- Implements production best practices\n",
    "- Is portfolio-ready for demonstration\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll understand:\n",
    "- How to architect a production RAG application\n",
    "- Streamlit fundamentals for RAG interfaces\n",
    "- State management for chat applications\n",
    "- Production deployment options\n",
    "- Performance optimization strategies\n",
    "- Monitoring and observability patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Application Architecture\n",
    "\n",
    "### 1.1 High-Level Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                    Streamlit Frontend                    ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ Query Input  ‚îÇ  ‚îÇ   Sidebar    ‚îÇ  ‚îÇ  Chat Display‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ  - Config    ‚îÇ  ‚îÇ  - Messages  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ              ‚îÇ  ‚îÇ  - Settings  ‚îÇ  ‚îÇ  - Sources   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                           ‚îÇ\n",
    "                           ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                   Application Layer                      ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ          RAG Configuration Manager               ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  - Basic RAG                                     ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  - RAG-Fusion                                    ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  - Filtered RAG                                  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  - Hardened RAG (recommended)                    ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ                                                          ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ            State Management                       ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  - Chat history                                  ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  - User preferences                              ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  - Session state                                 ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                           ‚îÇ\n",
    "                           ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                     Data Layer                           ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ   Chroma DB  ‚îÇ  ‚îÇ   OpenAI     ‚îÇ  ‚îÇ  LangSmith   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  (Vectors)   ‚îÇ  ‚îÇ  (LLM/Embed) ‚îÇ  ‚îÇ  (Tracing)   ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### 1.2 Project Structure\n",
    "\n",
    "```\n",
    "security-rag-from-scratch/\n",
    "‚îú‚îÄ‚îÄ app/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ app.py                 # Main Streamlit application\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ utils.py               # Utility functions\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configuration management\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ rag_configs/           # RAG configuration implementations\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ basic_rag.py\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ fusion_rag.py\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ filtered_rag.py\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ hardened_rag.py\n",
    "‚îú‚îÄ‚îÄ .env                       # Environment variables (not in git)\n",
    "‚îú‚îÄ‚îÄ .env.example               # Example environment file\n",
    "‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies\n",
    "‚îú‚îÄ‚îÄ Dockerfile                 # Docker configuration\n",
    "‚îî‚îÄ‚îÄ docker-compose.yml         # Docker Compose setup\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Streamlit Application Components\n",
    "\n",
    "### 2.1 Key Features\n",
    "\n",
    "Our Streamlit app includes:\n",
    "\n",
    "1. **Query Interface**\n",
    "   - Text input with submit button\n",
    "   - Example queries for quick testing\n",
    "   - Clear chat button\n",
    "\n",
    "2. **Configuration Sidebar**\n",
    "   - RAG configuration selector\n",
    "   - Temperature slider\n",
    "   - Top-k retrieval control\n",
    "   - Security settings toggle\n",
    "\n",
    "3. **Chat Display**\n",
    "   - Message history (user + assistant)\n",
    "   - Streaming responses\n",
    "   - Source citations\n",
    "   - Confidence indicators\n",
    "   - Security warnings (if applicable)\n",
    "\n",
    "4. **Metrics Dashboard**\n",
    "   - Response latency\n",
    "   - Retrieval quality\n",
    "   - Confidence scores\n",
    "   - Usage statistics\n",
    "\n",
    "### 2.2 State Management\n",
    "\n",
    "Streamlit's `st.session_state` manages:\n",
    "\n",
    "```python\n",
    "# Initialize session state\n",
    "if 'messages' not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "if 'rag_config' not in st.session_state:\n",
    "    st.session_state.rag_config = 'hardened'\n",
    "\n",
    "if 'chat_history' not in st.session_state:\n",
    "    st.session_state.chat_history = []\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Production Best Practices\n",
    "\n",
    "### 3.1 Environment Management\n",
    "\n",
    "```bash\n",
    "# .env.example\n",
    "OPENAI_API_KEY=your-openai-api-key\n",
    "LANGCHAIN_TRACING_V2=true\n",
    "LANGCHAIN_API_KEY=your-langsmith-key\n",
    "LANGCHAIN_PROJECT=security-rag-production\n",
    "\n",
    "# Vector store configuration\n",
    "CHROMA_PERSIST_DIR=./chroma_db\n",
    "CHROMA_COLLECTION_NAME=owasp_security\n",
    "\n",
    "# Application settings\n",
    "APP_TITLE=AI Security Analyst Assistant\n",
    "APP_ICON=üîê\n",
    "DEFAULT_MODEL=gpt-4\n",
    "DEFAULT_TEMPERATURE=0.0\n",
    "DEFAULT_TOP_K=3\n",
    "\n",
    "# Security settings\n",
    "ENABLE_ADVERSARIAL_DETECTION=true\n",
    "ENABLE_SOURCE_VERIFICATION=true\n",
    "ENABLE_CONFIDENCE_SCORING=true\n",
    "ENABLE_PII_REDACTION=true\n",
    "```\n",
    "\n",
    "### 3.2 Error Handling\n",
    "\n",
    "```python\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def safe_query(rag_system, query: str):\n",
    "    \"\"\"Execute query with error handling.\"\"\"\n",
    "    try:\n",
    "        result = rag_system.query(query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Query failed: {e}\")\n",
    "        return {\n",
    "            \"answer\": \"I encountered an error processing your request. Please try again.\",\n",
    "            \"error\": True,\n",
    "        }\n",
    "```\n",
    "\n",
    "### 3.3 Caching\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "\n",
    "@st.cache_resource\n",
    "def load_vectorstore():\n",
    "    \"\"\"Load vector store (cached).\"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        embedding_function=embeddings,\n",
    "    )\n",
    "    return vectorstore\n",
    "\n",
    "@st.cache_resource\n",
    "def load_llm(model: str, temperature: float):\n",
    "    \"\"\"Load LLM (cached by parameters).\"\"\"\n",
    "    return ChatOpenAI(model=model, temperature=temperature)\n",
    "```\n",
    "\n",
    "### 3.4 Monitoring\n",
    "\n",
    "```python\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def log_query_metrics(query: str, result: dict, latency_ms: float):\n",
    "    \"\"\"Log query metrics for monitoring.\"\"\"\n",
    "    metrics = {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"query\": query,\n",
    "        \"latency_ms\": latency_ms,\n",
    "        \"confidence\": result.get(\"confidence\", {}).get(\"overall\", 0),\n",
    "        \"blocked\": result.get(\"blocked\", False),\n",
    "        \"sources_count\": len(result.get(\"sources\", [])),\n",
    "    }\n",
    "    logger.info(f\"Query metrics: {metrics}\")\n",
    "    # In production, send to monitoring service (e.g., Datadog, CloudWatch)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deployment Options\n",
    "\n",
    "### 4.1 Local Development\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Set environment variables\n",
    "cp .env.example .env\n",
    "# Edit .env with your API keys\n",
    "\n",
    "# Run Streamlit app\n",
    "streamlit run app/app.py\n",
    "\n",
    "# App will be available at http://localhost:8501\n",
    "```\n",
    "\n",
    "### 4.2 Docker Deployment\n",
    "\n",
    "```dockerfile\n",
    "# Dockerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# Install dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# Copy application\n",
    "COPY app/ ./app/\n",
    "COPY notebooks/ ./notebooks/\n",
    "COPY data/ ./data/\n",
    "\n",
    "# Expose Streamlit port\n",
    "EXPOSE 8501\n",
    "\n",
    "# Health check\n",
    "HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health\n",
    "\n",
    "# Run app\n",
    "CMD [\"streamlit\", \"run\", \"app/app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]\n",
    "```\n",
    "\n",
    "```yaml\n",
    "# docker-compose.yml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  app:\n",
    "    build: .\n",
    "    ports:\n",
    "      - \"8501:8501\"\n",
    "    environment:\n",
    "      - OPENAI_API_KEY=${OPENAI_API_KEY}\n",
    "      - LANGCHAIN_TRACING_V2=${LANGCHAIN_TRACING_V2}\n",
    "      - LANGCHAIN_API_KEY=${LANGCHAIN_API_KEY}\n",
    "    volumes:\n",
    "      - ./chroma_db:/app/chroma_db\n",
    "    restart: unless-stopped\n",
    "```\n",
    "\n",
    "```bash\n",
    "# Build and run with Docker Compose\n",
    "docker-compose up --build\n",
    "```\n",
    "\n",
    "### 4.3 Streamlit Cloud\n",
    "\n",
    "1. Push code to GitHub\n",
    "2. Go to https://share.streamlit.io/\n",
    "3. Connect your repository\n",
    "4. Add secrets in Streamlit Cloud UI:\n",
    "   - `OPENAI_API_KEY`\n",
    "   - `LANGCHAIN_API_KEY`\n",
    "5. Deploy!\n",
    "\n",
    "**Advantages:**\n",
    "- Free for public apps\n",
    "- Automatic SSL\n",
    "- Easy sharing\n",
    "- Auto-deploy on git push\n",
    "\n",
    "**Limitations:**\n",
    "- Resource constraints\n",
    "- Public visibility (unless Pro)\n",
    "- Limited compute\n",
    "\n",
    "### 4.4 Cloud Deployment (AWS/GCP/Azure)\n",
    "\n",
    "#### AWS Elastic Beanstalk\n",
    "\n",
    "```bash\n",
    "# Install EB CLI\n",
    "pip install awsebcli\n",
    "\n",
    "# Initialize EB application\n",
    "eb init -p python-3.11 security-rag-app\n",
    "\n",
    "# Create environment\n",
    "eb create security-rag-prod\n",
    "\n",
    "# Deploy\n",
    "eb deploy\n",
    "\n",
    "# Open app\n",
    "eb open\n",
    "```\n",
    "\n",
    "#### Google Cloud Run\n",
    "\n",
    "```bash\n",
    "# Build container\n",
    "gcloud builds submit --tag gcr.io/PROJECT_ID/security-rag\n",
    "\n",
    "# Deploy to Cloud Run\n",
    "gcloud run deploy security-rag \\\n",
    "  --image gcr.io/PROJECT_ID/security-rag \\\n",
    "  --platform managed \\\n",
    "  --region us-central1 \\\n",
    "  --allow-unauthenticated\n",
    "```\n",
    "\n",
    "#### Azure Container Apps\n",
    "\n",
    "```bash\n",
    "# Create container app\n",
    "az containerapp create \\\n",
    "  --name security-rag \\\n",
    "  --resource-group myResourceGroup \\\n",
    "  --image myregistry.azurecr.io/security-rag:latest \\\n",
    "  --target-port 8501 \\\n",
    "  --ingress external\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Optimization\n",
    "\n",
    "### 5.1 Vector Store Optimization\n",
    "\n",
    "```python\n",
    "# Pre-load and cache vector store\n",
    "@st.cache_resource\n",
    "def get_vectorstore():\n",
    "    return Chroma(\n",
    "        persist_directory=\"./chroma_db\",\n",
    "        embedding_function=OpenAIEmbeddings(),\n",
    "    )\n",
    "\n",
    "# Use connection pooling for database connections\n",
    "vectorstore = get_vectorstore()\n",
    "```\n",
    "\n",
    "### 5.2 Response Streaming\n",
    "\n",
    "```python\n",
    "def stream_response(query: str):\n",
    "    \"\"\"Stream LLM response for better UX.\"\"\"\n",
    "    placeholder = st.empty()\n",
    "    full_response = \"\"\n",
    "    \n",
    "    for chunk in llm.stream(query):\n",
    "        full_response += chunk.content\n",
    "        placeholder.markdown(full_response + \"‚ñå\")\n",
    "    \n",
    "    placeholder.markdown(full_response)\n",
    "    return full_response\n",
    "```\n",
    "\n",
    "### 5.3 Async Operations\n",
    "\n",
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def parallel_retrieval(queries: List[str]):\n",
    "    \"\"\"Retrieve from multiple queries in parallel.\"\"\"\n",
    "    tasks = [vectorstore.asimilarity_search(q) for q in queries]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    return results\n",
    "```\n",
    "\n",
    "### 5.4 Batch Processing\n",
    "\n",
    "```python\n",
    "# Batch embed queries for efficiency\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    chunk_size=100,  # Process 100 texts at once\n",
    "    max_retries=3,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Security Considerations\n",
    "\n",
    "### 6.1 API Key Management\n",
    "\n",
    "```python\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load from .env file (development)\n",
    "load_dotenv()\n",
    "\n",
    "# Or use Streamlit secrets (production)\n",
    "import streamlit as st\n",
    "\n",
    "def get_api_key(key_name: str) -> str:\n",
    "    \"\"\"Get API key from environment or Streamlit secrets.\"\"\"\n",
    "    # Try Streamlit secrets first (production)\n",
    "    try:\n",
    "        return st.secrets[key_name]\n",
    "    except:\n",
    "        # Fall back to environment variables (development)\n",
    "        return os.getenv(key_name)\n",
    "```\n",
    "\n",
    "### 6.2 Rate Limiting\n",
    "\n",
    "```python\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict\n",
    "\n",
    "class RateLimiter:\n",
    "    def __init__(self, max_requests: int = 10, window_minutes: int = 1):\n",
    "        self.max_requests = max_requests\n",
    "        self.window = timedelta(minutes=window_minutes)\n",
    "        self.requests = defaultdict(list)\n",
    "    \n",
    "    def allow_request(self, user_id: str) -> bool:\n",
    "        now = datetime.now()\n",
    "        cutoff = now - self.window\n",
    "        \n",
    "        # Remove old requests\n",
    "        self.requests[user_id] = [\n",
    "            req for req in self.requests[user_id] if req > cutoff\n",
    "        ]\n",
    "        \n",
    "        if len(self.requests[user_id]) >= self.max_requests:\n",
    "            return False\n",
    "        \n",
    "        self.requests[user_id].append(now)\n",
    "        return True\n",
    "\n",
    "# Usage in Streamlit\n",
    "if 'rate_limiter' not in st.session_state:\n",
    "    st.session_state.rate_limiter = RateLimiter(max_requests=10, window_minutes=1)\n",
    "\n",
    "user_id = st.session_state.get('user_id', 'anonymous')\n",
    "\n",
    "if not st.session_state.rate_limiter.allow_request(user_id):\n",
    "    st.error(\"Rate limit exceeded. Please wait before sending another query.\")\n",
    "    st.stop()\n",
    "```\n",
    "\n",
    "### 6.3 Input Sanitization\n",
    "\n",
    "```python\n",
    "def sanitize_input(text: str, max_length: int = 1000) -> str:\n",
    "    \"\"\"Sanitize user input.\"\"\"\n",
    "    # Limit length\n",
    "    text = text[:max_length]\n",
    "    \n",
    "    # Remove potentially harmful characters\n",
    "    # (In practice, use a proper sanitization library)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. User Experience Enhancements\n",
    "\n",
    "### 7.1 Example Queries\n",
    "\n",
    "```python\n",
    "EXAMPLE_QUERIES = [\n",
    "    \"What is prompt injection and how do I defend against it?\",\n",
    "    \"Explain model extraction attacks and mitigations\",\n",
    "    \"What are the top LLM security risks?\",\n",
    "    \"How do I secure my ML training pipeline?\",\n",
    "    \"What is the OWASP Top 10 for LLMs?\",\n",
    "]\n",
    "\n",
    "# In sidebar\n",
    "st.sidebar.subheader(\"Example Queries\")\n",
    "for example in EXAMPLE_QUERIES:\n",
    "    if st.sidebar.button(example, key=example):\n",
    "        st.session_state.current_query = example\n",
    "```\n",
    "\n",
    "### 7.2 Loading Indicators\n",
    "\n",
    "```python\n",
    "with st.spinner(\"Thinking...\"):\n",
    "    result = rag_system.query(query)\n",
    "\n",
    "# Or with progress bar\n",
    "progress_bar = st.progress(0)\n",
    "for i in range(100):\n",
    "    time.sleep(0.01)\n",
    "    progress_bar.progress(i + 1)\n",
    "```\n",
    "\n",
    "### 7.3 Feedback Collection\n",
    "\n",
    "```python\n",
    "# Thumbs up/down for responses\n",
    "col1, col2 = st.columns([1, 1])\n",
    "with col1:\n",
    "    if st.button(\"üëç Helpful\"):\n",
    "        log_feedback(query, result, positive=True)\n",
    "        st.success(\"Thanks for your feedback!\")\n",
    "with col2:\n",
    "    if st.button(\"üëé Not Helpful\"):\n",
    "        log_feedback(query, result, positive=False)\n",
    "        st.info(\"Thanks! We'll improve.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this final notebook, we've designed a production-ready RAG deployment:\n",
    "\n",
    "### Application Architecture\n",
    "\n",
    "- **3-tier architecture**: Frontend (Streamlit) ‚Üí Application (RAG configs) ‚Üí Data (Vector DB, LLM)\n",
    "- **Modular design**: Pluggable RAG configurations\n",
    "- **State management**: Chat history, preferences, session state\n",
    "\n",
    "### Key Features\n",
    "\n",
    "1. **Interactive Query Interface**\n",
    "   - Text input with examples\n",
    "   - Real-time responses\n",
    "   - Chat history\n",
    "\n",
    "2. **Configuration Options**\n",
    "   - Multiple RAG strategies\n",
    "   - Temperature control\n",
    "   - Top-k retrieval\n",
    "   - Security toggles\n",
    "\n",
    "3. **Rich Display**\n",
    "   - Source citations\n",
    "   - Confidence indicators\n",
    "   - Security warnings\n",
    "   - Metrics dashboard\n",
    "\n",
    "### Production Best Practices\n",
    "\n",
    "- **Environment management**: `.env` files, Streamlit secrets\n",
    "- **Error handling**: Try-catch, graceful degradation\n",
    "- **Caching**: `@st.cache_resource` for expensive operations\n",
    "- **Monitoring**: Query metrics, latency tracking\n",
    "- **Security**: Rate limiting, input sanitization, API key protection\n",
    "\n",
    "### Deployment Options\n",
    "\n",
    "1. **Local**: `streamlit run app/app.py`\n",
    "2. **Docker**: Containerized deployment\n",
    "3. **Streamlit Cloud**: Free, easy sharing\n",
    "4. **Cloud Platforms**: AWS, GCP, Azure\n",
    "\n",
    "### Performance Optimization\n",
    "\n",
    "- Vector store caching\n",
    "- Response streaming\n",
    "- Async operations\n",
    "- Batch processing\n",
    "\n",
    "### Next Steps: Run the Demo!\n",
    "\n",
    "```bash\n",
    "# Navigate to app directory\n",
    "cd app\n",
    "\n",
    "# Run Streamlit app\n",
    "streamlit run app.py\n",
    "\n",
    "# Visit http://localhost:8501\n",
    "```\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the **Security RAG from Scratch** tutorial series!\n",
    "\n",
    "### What You've Built\n",
    "\n",
    "- ‚úÖ 11 comprehensive notebooks\n",
    "- ‚úÖ 9 different RAG techniques\n",
    "- ‚úÖ Complete evaluation framework\n",
    "- ‚úÖ Production-ready application\n",
    "- ‚úÖ Portfolio-quality demonstration\n",
    "\n",
    "### Skills You've Mastered\n",
    "\n",
    "1. **RAG Fundamentals**: Retrieval, embeddings, vector stores, generation\n",
    "2. **Advanced Techniques**: Multi-query, fusion, decomposition, reranking, RAPTOR, ColBERT\n",
    "3. **Security**: Adversarial detection, hardening, source verification, confidence scoring\n",
    "4. **Evaluation**: Metrics, benchmarking, human evaluation\n",
    "5. **Production**: Deployment, monitoring, optimization, best practices\n",
    "\n",
    "### Portfolio Presentation\n",
    "\n",
    "**Elevator Pitch:**\n",
    "\n",
    "> \"I built an AI Security Analyst Assistant using RAG to help security teams navigate complex frameworks like MITRE ATT&CK and OWASP. I implemented 9 advanced retrieval techniques including ColBERT for token-level matching and RAPTOR for hierarchical knowledge, evaluated them with quantitative metrics, and hardened the system against adversarial attacks. The production deployment showcases interactive querying with confidence scoring and source citation.\"\n",
    "\n",
    "**GitHub Repository:**\n",
    "- ‚úÖ Clear README with setup instructions\n",
    "- ‚úÖ 11 educational notebooks with explanations\n",
    "- ‚úÖ Working demo application\n",
    "- ‚úÖ Comprehensive documentation\n",
    "- ‚úÖ Production deployment guide\n",
    "\n",
    "**Demo Video Script:**\n",
    "1. Show problem: Security analysts need AI assistance\n",
    "2. Explain solution: RAG system with security focus\n",
    "3. Live demo: Ask security questions, show responses with sources\n",
    "4. Technical deep-dive: Explain one advanced technique (e.g., ColBERT)\n",
    "5. Results: Show evaluation metrics and comparisons\n",
    "6. Future work: Additional features, more data sources\n",
    "\n",
    "### Thank You!\n",
    "\n",
    "This has been a comprehensive journey through building production RAG systems. You now have:\n",
    "- Deep understanding of RAG architecture\n",
    "- Hands-on experience with advanced techniques\n",
    "- Portfolio-ready project\n",
    "- Foundation for building your own RAG applications\n",
    "\n",
    "**Keep building, keep learning, and stay secure! üîê**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
